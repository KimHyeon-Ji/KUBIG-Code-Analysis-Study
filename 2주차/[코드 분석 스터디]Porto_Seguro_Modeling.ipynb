{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Porto_Seguro_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ue_PcizP0VeO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNB8rv5MOxtQ",
        "outputId": "22f8ca56-57bb-44cd-c541-d3a222b9a78a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IthOGtrOOvYw"
      },
      "source": [
        "MAX_ROUNDS = 400 \n",
        "OPTIMIZE_ROUNDS = False\n",
        "LEARNING_RATE = 0.07\n",
        "EARLY_STOPPING_RATE=50"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVnnhA9S6KfF"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numba import jit\n",
        "import time\n",
        "import gc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OKV_DaM8LPb"
      },
      "source": [
        "Module Numba\n",
        "\n",
        "모델의 성능 향상에 관여하는 모듈\n",
        "\n",
        "<공식문서>\n",
        "\n",
        "\"Numba makes Python code fast.\n",
        "Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code.\"\n",
        "\n",
        "-> 넘파이 코드를 빠르게 실행시켜주는 JIT 컴파일러 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2FfHkDz7M-L"
      },
      "source": [
        "# 지니 계수 계산 코드\n",
        "\n",
        "@jit\n",
        "def eval_gini(y_true, y_prob) :\n",
        "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
        "  y_true = y_true[np.argsort(y_prob)]\n",
        "  ntrue= 0\n",
        "  gini =0 \n",
        "  delta = 0\n",
        "  n=len(y_true)\n",
        "  for i in range(n-1,-1,-1) :\n",
        "    y_i = y_true[i]\n",
        "    ntrue += y_i\n",
        "    gini += y_i * delta\n",
        "    delta += 1-y_i\n",
        "  gini = 1-2*gini/(ntrue*(n-ntrue))\n",
        "  return gini"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckIZwPRF8aZ1"
      },
      "source": [
        "## 지니계수 계산 공식\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "## 지니계수 계산 코드\n",
        "\n",
        "\n",
        "```\n",
        "def gini(list_of_values):\n",
        "    sorted_list = sorted(list_of_values)\n",
        "    height, area = 0, 0\n",
        "    for value in sorted_list:\n",
        "        height += value\n",
        "        area += height - value / 2.\n",
        "    fair_area = height * len(list_of_values) / 2.\n",
        "    return (fair_area - area) / fair_area\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiWWLZSyWvoy"
      },
      "source": [
        "아래 코드에서 분류에 사용한 XGBClassifier모델은 평가 지표로 rmse와 같은 값을 사용 -> 즉 오류의 최솟값을 찾음\n",
        "\n",
        "이 대회의 평가 지표인 지니 계수 : 0.5에 가까울수록(값이 클수록) 좋은 값이기 때문에 -를 붙여주는 함수를 생성."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-31bEM8w-yTu"
      },
      "source": [
        "def gini_xgb(preds, dtrain) :\n",
        "  labels = dtrain.get_label()\n",
        "  gini_score = -eval_gini(labels,preds)\n",
        "  return [('gini',gini_score)]\n",
        "\n",
        "def add_noise(series, noise_level):\n",
        "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
        "\n",
        "def target_encode(trn_series=None,   \n",
        "                  val_series=None,\n",
        "                  tst_series=None,\n",
        "                  target=None,\n",
        "                  min_samples_leaf=1,\n",
        "                  smoothing=1,\n",
        "                  noise_level=0):\n",
        "  \n",
        "    assert len(trn_series) == len(target)\n",
        "    assert trn_series.name == tst_series.name\n",
        "    temp = pd.concat([trn_series, target], axis=1)\n",
        "   \n",
        "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
        "   \n",
        "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
        "    \n",
        "    prior = target.mean()\n",
        "\n",
        "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
        "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
        "\n",
        "    ft_trn_series = pd.merge(\n",
        "        trn_series.to_frame(trn_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=trn_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "\n",
        "    ft_trn_series.index = trn_series.index\n",
        "    ft_val_series = pd.merge(\n",
        "        val_series.to_frame(val_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=val_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "\n",
        "    ft_val_series.index = val_series.index\n",
        "    ft_tst_series = pd.merge(\n",
        "        tst_series.to_frame(tst_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=tst_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "\n",
        "    ft_tst_series.index = tst_series.index\n",
        "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCsm68E5_XOB"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/KUBIG/KaggleStudy/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/KUBIG/KaggleStudy/data/test.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAKlq5q7_hQM"
      },
      "source": [
        "train_features = [\n",
        "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
        "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
        "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
        "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
        "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
        "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
        "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
        "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
        "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
        "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
        "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
        "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
        "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
        "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
        "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
        "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
        "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
        "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
        "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
        "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
        "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
        "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
        "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
        "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
        "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
        "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
        "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
        "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
        "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
        "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
        "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
        "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
        "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
        "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
        "]\n",
        "# add combinations\n",
        "combs = [\n",
        "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
        "    ('ps_reg_01', 'ps_car_04_cat'),\n",
        "]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDcqJvnB0ja3"
      },
      "source": [
        "라벨 인코딩\n",
        "\n",
        "https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=wideeyed&logNo=221592651246"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIxYwJdTAvE_",
        "outputId": "2b5bc2d5-ba71-4990-ecd4-5c3df9d928d3"
      },
      "source": [
        "id_train = train['id'].values\n",
        "id_test = test['id'].values\n",
        "y=train['target']\n",
        "\n",
        "start = time.time()\n",
        "for n_c, (f1,f2) in enumerate(combs) : # enumerate : 인덱스 번호와 컬렉션 원소를 tuple 형태로 반환\n",
        "  name1 = f1 + \"_plus_\" + f2\n",
        "  print('current feature %60s %4d in %5.1f'\n",
        "        % (name1, n_c +1, (time.time()-start)/60), end='')\n",
        "  print('\\r'*75, end = '')\n",
        "  train[name1] = train[f1].apply(lambda x : str(x)) + \"_\" + train[f2].apply(lambda x : str(x))\n",
        "  test[name1] = test[f1].apply(lambda x : str(x)) + \"_\" + test[f2].apply(lambda x : str(x))\n",
        "\n",
        "  lbl = LabelEncoder()\n",
        "  lbl.fit(list(train[name1].values) + list(test[name1].values)) \n",
        "  # test셋에서만 등장한 라벨이 존재할 수 있기 때문에 train, test 모두에서 등장한 라벨들에 대해 fitting해줘야 함\n",
        "  train[name1] = lbl.transform(list(train[name1].values))\n",
        "  test[name1] = lbl.transform(list(test[name1].values))\n",
        "\n",
        "  train_features.append(name1)\n",
        "\n",
        "X = train[train_features]\n",
        "test = test[train_features]\n",
        "\n",
        "f_cats = [f for f in X.columns if \"_cat\" in f]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZrSMjcgEKoP"
      },
      "source": [
        "y_valid_pred = 0*y\n",
        "y_test_pred = 0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVn4ravuItCk"
      },
      "source": [
        "K = 5\n",
        "kf = KFold(n_splits= K, random_state=1, shuffle = True)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vybr2C4aI7Sz"
      },
      "source": [
        "model = XGBClassifier(\n",
        "    n_estimators = MAX_ROUNDS, \n",
        "    max_depth = 4,\n",
        "    objective = 'binary:logistic', # target : binary 값이므로 학습 목표를 명확히 지정\n",
        "    learning_rate = LEARNING_RATE,\n",
        "    subsample = .8, # 데이터의 0.8을 데이터 생성에 사용\n",
        "    min_child_weight = 6,\n",
        "    colsample_bytree = .8, # 각 트리에 얼마의 column을 이용해서 구성할 것인지\n",
        "    scale_pos_weight = 1.6,\n",
        "    gamma = 10,\n",
        "    reg_alpha=10,\n",
        "    reg_lambda=1.3\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EORv6sfshtq",
        "outputId": "205634e8-9c2a-44dd-dcc6-87373139c374"
      },
      "source": [
        "for i, (train_index, test_index) in enumerate(kf.split(train)) :\n",
        "\n",
        "  y_train,y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
        "  X_train,X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index, :].copy()\n",
        "  X_test = test.copy()\n",
        "  print(\"\\nFold\", i )\n",
        "\n",
        "  for f in f_cats :\n",
        "    X_train[f + \"_avg\"], X_valid[f+'_avg'], X_test[f+\"_avg\"] = target_encode(\n",
        "    trn_series= X_train[f],\n",
        "    val_series=X_valid[f],\n",
        "    tst_series=X_test[f],\n",
        "    target=y_train,\n",
        "    min_samples_leaf=200,\n",
        "    smoothing=10,\n",
        "    noise_level=0)\n",
        "  if OPTIMIZE_ROUNDS : \n",
        "    eval_set = [(X_valid,y_valid)]\n",
        "    fit_model = model.fit(X_train,y_train, eval_set=eval_set,\n",
        "                          eval_metric=gini_xgb,\n",
        "                          early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n",
        "                          verbose=False)\n",
        "    print(\"Best N trees = \", model.best_ntree_limit)\n",
        "    print(\"Best gini = \",model.best_score)\n",
        "  else :\n",
        "    fit_model = model.fit(X_train,y_train)\n",
        "\n",
        "  pred = fit_model.predict_proba(X_valid)[:,1] # 1로 분류될 확률에 대한 열을 가져옴\n",
        "  print(\"Gini = \", eval_gini(y_valid,pred))\n",
        "  y_valid_pred.iloc[test_index] = pred\n",
        "\n",
        "  y_test_pred += fit_model.predict_proba(X_test)[:,1] \n",
        "\n",
        "  del X_test, X_train, X_valid, y_train\n",
        "\n",
        "print(\"\\nGini for full training set : \")\n",
        "eval_gini(y,y_valid_pred)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4c8cec391835>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-4-4c8cec391835> (5)\n",
            "\n",
            "File \"<ipython-input-4-4c8cec391835>\", line 5:\n",
            "def eval_gini(y_true, y_prob) :\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  @jit\n",
            "<ipython-input-4-4c8cec391835>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-4-4c8cec391835>\", line 11:\n",
            "def eval_gini(y_true, y_prob) :\n",
            "    <source elided>\n",
            "  n=len(y_true)\n",
            "  for i in range(n-1,-1,-1) :\n",
            "  ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-4-4c8cec391835>\", line 5:\n",
            "def eval_gini(y_true, y_prob) :\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-4-4c8cec391835>\", line 5:\n",
            "def eval_gini(y_true, y_prob) :\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  state.func_ir.loc))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini =  0.28567263218972716\n",
            "\n",
            "Fold 1\n",
            "Gini =  0.2819863577751057\n",
            "\n",
            "Fold 2\n",
            "Gini =  0.2744086703325922\n",
            "\n",
            "Fold 3\n",
            "Gini =  0.3004816619590289\n",
            "\n",
            "Fold 4\n",
            "Gini =  0.2826294177005454\n",
            "\n",
            "Gini for full training set : \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4c8cec391835>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"eval_gini\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-4-4c8cec391835> (5)\n",
            "\n",
            "File \"<ipython-input-4-4c8cec391835>\", line 5:\n",
            "def eval_gini(y_true, y_prob) :\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  @jit\n",
            "<ipython-input-4-4c8cec391835>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"eval_gini\" failed type inference due to: cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-4-4c8cec391835>\", line 11:\n",
            "def eval_gini(y_true, y_prob) :\n",
            "    <source elided>\n",
            "  n=len(y_true)\n",
            "  for i in range(n-1,-1,-1) :\n",
            "  ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"eval_gini\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-4-4c8cec391835>\", line 5:\n",
            "def eval_gini(y_true, y_prob) :\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-4-4c8cec391835>\", line 5:\n",
            "def eval_gini(y_true, y_prob) :\n",
            "  y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
            "  ^\n",
            "\n",
            "  state.func_ir.loc))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28481022678880197"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufXwlv5IT4lm"
      },
      "source": [
        "Another Example\n",
        "\n",
        "https://www.kaggle.com/rshally/porto-xgb-lgb-kfold-lb-0-282"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGK9sqjYP57t"
      },
      "source": [
        "val = pd.DataFrame()\n",
        "val['id'] = id_train\n",
        "val['target']= y_valid_pred.values\n",
        "val.to_csv('/content/drive/MyDrive/KUBIG/KaggleStudy/Porto_Seguro\\'s_Safe_Driver_Prediction/xgb_valid.csv', float_format=\"%.6f\", index=False)  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s3cu963vxVX"
      },
      "source": [
        "sub=pd.DataFrame()\n",
        "sub['id'] = id_test\n",
        "sub['target'] = y_test_pred\n",
        "sub.to_csv('/content/drive/MyDrive/KUBIG/KaggleStudy/Porto_Seguro\\'s_Safe_Driver_Prediction/xgb_submit.csv', float_format=\"%.6f\",index=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue_PcizP0VeO"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_4gUegDVHQoi",
        "outputId": "b9c84a35-b298-4b1f-baec-1b9203e5b785"
      },
      "source": [
        "name1 = 'ps_reg_01' + \"_plus_\" + 'ps_car_02_cat'\n",
        "name1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ps_reg_01_plus_ps_car_02_cat'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ODXll9HOIk",
        "outputId": "7e9a04a3-df09-4096-aeda-ebb2a41eeee4"
      },
      "source": [
        "train[name1] = train['ps_reg_01'].apply(lambda x : str(x)) + \"_\" + train['ps_car_02_cat'].apply(lambda x : str(x))\n",
        "test[name1] = test['ps_reg_01'].apply(lambda x : str(x)) + \"_\" + test['ps_car_02_cat'].apply(lambda x : str(x))\n",
        "list(train[name1].values) + list(test[name1].values)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0.7_1',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_0',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.5_1',\n",
              " '0.9_0',\n",
              " '0.5_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.4_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.7_1',\n",
              " '0.6_0',\n",
              " '0.2_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.2_0',\n",
              " '0.9_0',\n",
              " '0.7_1',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_0',\n",
              " '0.8_0',\n",
              " '0.5_1',\n",
              " '0.7_1',\n",
              " '0.6_1',\n",
              " '0.3_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.6_1',\n",
              " '0.3_1',\n",
              " '0.4_1',\n",
              " '0.9_0',\n",
              " '0.6_1',\n",
              " '0.5_1',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.3_1',\n",
              " '0.2_1',\n",
              " '0.8_1',\n",
              " '0.9_0',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.7_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.4_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.1_0',\n",
              " '0.6_1',\n",
              " '0.0_1',\n",
              " '0.4_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.8_1',\n",
              " '0.3_0',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.2_1',\n",
              " '0.3_1',\n",
              " '0.7_1',\n",
              " '0.7_0',\n",
              " '0.0_1',\n",
              " '0.7_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.5_1',\n",
              " '0.8_1',\n",
              " '0.8_0',\n",
              " '0.1_1',\n",
              " '0.2_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.0_1',\n",
              " '0.9_0',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.2_1',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.2_0',\n",
              " '0.4_1',\n",
              " '0.7_1',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.6_1',\n",
              " '0.9_0',\n",
              " '0.9_0',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.3_1',\n",
              " '0.1_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.4_1',\n",
              " '0.5_0',\n",
              " '0.4_0',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.5_1',\n",
              " '0.8_0',\n",
              " '0.0_0',\n",
              " '0.6_1',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.9_0',\n",
              " '0.1_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.7_0',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.5_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.6_1',\n",
              " '0.7_0',\n",
              " '0.7_0',\n",
              " '0.7_1',\n",
              " '0.6_1',\n",
              " '0.5_1',\n",
              " '0.1_1',\n",
              " '0.8_1',\n",
              " '0.9_0',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.8_1',\n",
              " '0.9_0',\n",
              " '0.6_1',\n",
              " '0.9_0',\n",
              " '0.2_1',\n",
              " '0.2_1',\n",
              " '0.4_0',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.7_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.7_0',\n",
              " '0.4_1',\n",
              " '0.5_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.5_0',\n",
              " '0.7_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.2_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.4_1',\n",
              " '0.8_1',\n",
              " '0.3_0',\n",
              " '0.4_1',\n",
              " '0.6_1',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.0_1',\n",
              " '0.3_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.5_1',\n",
              " '0.6_1',\n",
              " '0.2_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.9_0',\n",
              " '0.9_0',\n",
              " '0.7_1',\n",
              " '0.5_1',\n",
              " '0.5_1',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.3_1',\n",
              " '0.5_1',\n",
              " '0.5_1',\n",
              " '0.5_1',\n",
              " '0.0_1',\n",
              " '0.8_0',\n",
              " '0.9_1',\n",
              " '0.6_0',\n",
              " '0.4_0',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.9_0',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.6_0',\n",
              " '0.9_0',\n",
              " '0.1_1',\n",
              " '0.3_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.6_0',\n",
              " '0.2_0',\n",
              " '0.5_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.3_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.5_1',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.3_1',\n",
              " '0.5_1',\n",
              " '0.7_1',\n",
              " '0.7_0',\n",
              " '0.7_1',\n",
              " '0.6_0',\n",
              " '0.6_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.3_0',\n",
              " '0.9_0',\n",
              " '0.8_0',\n",
              " '0.9_0',\n",
              " '0.8_1',\n",
              " '0.1_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.4_0',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.4_1',\n",
              " '0.1_0',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.7_1',\n",
              " '0.2_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.2_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.3_0',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.7_1',\n",
              " '0.2_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.8_1',\n",
              " '0.6_1',\n",
              " '0.4_1',\n",
              " '0.6_1',\n",
              " '0.4_0',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.4_1',\n",
              " '0.6_0',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_0',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.3_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.3_0',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.1_1',\n",
              " '0.6_1',\n",
              " '0.4_1',\n",
              " '0.3_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.9_0',\n",
              " '0.7_1',\n",
              " '0.7_0',\n",
              " '0.4_1',\n",
              " '0.5_1',\n",
              " '0.8_1',\n",
              " '0.2_1',\n",
              " '0.2_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.8_1',\n",
              " '0.2_0',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.3_1',\n",
              " '0.6_1',\n",
              " '0.6_0',\n",
              " '0.8_1',\n",
              " '0.7_0',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.2_1',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.4_1',\n",
              " '0.2_1',\n",
              " '0.2_1',\n",
              " '0.6_1',\n",
              " '0.9_0',\n",
              " '0.9_0',\n",
              " '0.7_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.8_0',\n",
              " '0.3_1',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.0_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.0_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.0_1',\n",
              " '0.7_1',\n",
              " '0.4_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.2_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.3_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.3_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.5_1',\n",
              " '0.5_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.0_1',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.9_0',\n",
              " '0.8_0',\n",
              " '0.7_0',\n",
              " '0.1_1',\n",
              " '0.2_1',\n",
              " '0.3_1',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.6_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.6_1',\n",
              " '0.0_1',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.7_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.9_0',\n",
              " '0.8_0',\n",
              " '0.8_0',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.7_0',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.8_0',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.4_1',\n",
              " '0.9_0',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.0_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.0_1',\n",
              " '0.9_0',\n",
              " '0.4_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.5_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.1_0',\n",
              " '0.4_1',\n",
              " '0.3_0',\n",
              " '0.7_1',\n",
              " '0.0_1',\n",
              " '0.8_1',\n",
              " '0.7_0',\n",
              " '0.8_1',\n",
              " '0.6_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.8_1',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.7_1',\n",
              " '0.6_1',\n",
              " '0.3_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.8_0',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.2_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.7_0',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.4_1',\n",
              " '0.6_1',\n",
              " '0.3_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.4_0',\n",
              " '0.0_1',\n",
              " '0.4_1',\n",
              " '0.2_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.7_0',\n",
              " '0.6_1',\n",
              " '0.4_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.8_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.4_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.3_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.6_1',\n",
              " '0.1_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.6_1',\n",
              " '0.3_1',\n",
              " '0.6_1',\n",
              " '0.2_1',\n",
              " '0.8_1',\n",
              " '0.6_1',\n",
              " '0.2_0',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.1_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_0',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.9_0',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.6_1',\n",
              " '0.5_1',\n",
              " '0.2_1',\n",
              " '0.1_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.4_0',\n",
              " '0.9_1',\n",
              " '0.5_0',\n",
              " '0.1_0',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.6_1',\n",
              " '0.1_1',\n",
              " '0.3_1',\n",
              " '0.1_1',\n",
              " '0.6_1',\n",
              " '0.3_0',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.4_0',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.6_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.4_1',\n",
              " '0.8_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.2_0',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.3_1',\n",
              " '0.0_0',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.6_1',\n",
              " '0.1_1',\n",
              " '0.4_0',\n",
              " '0.6_1',\n",
              " '0.3_1',\n",
              " '0.3_1',\n",
              " '0.5_1',\n",
              " '0.9_1',\n",
              " '0.4_0',\n",
              " '0.5_0',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.1_1',\n",
              " '0.3_0',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.0_0',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.4_1',\n",
              " '0.4_0',\n",
              " '0.9_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.4_1',\n",
              " '0.1_1',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.6_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.7_1',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.6_1',\n",
              " '0.0_1',\n",
              " '0.4_1',\n",
              " '0.8_0',\n",
              " '0.9_1',\n",
              " '0.0_1',\n",
              " '0.2_1',\n",
              " '0.3_1',\n",
              " '0.2_1',\n",
              " '0.4_0',\n",
              " '0.9_0',\n",
              " '0.3_1',\n",
              " '0.1_1',\n",
              " '0.3_1',\n",
              " '0.9_0',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.3_1',\n",
              " '0.1_0',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.4_1',\n",
              " '0.0_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.4_1',\n",
              " '0.7_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.4_0',\n",
              " '0.5_1',\n",
              " '0.8_0',\n",
              " '0.1_1',\n",
              " '0.3_0',\n",
              " '0.0_1',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.5_1',\n",
              " '0.3_1',\n",
              " '0.1_1',\n",
              " '0.7_1',\n",
              " '0.0_1',\n",
              " '0.7_1',\n",
              " '0.8_0',\n",
              " '0.2_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.9_0',\n",
              " '0.1_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.2_1',\n",
              " '0.3_1',\n",
              " '0.4_1',\n",
              " '0.0_0',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.7_1',\n",
              " '0.8_1',\n",
              " '0.9_0',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.8_1',\n",
              " '0.8_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.3_1',\n",
              " '0.9_1',\n",
              " '0.1_0',\n",
              " '0.2_1',\n",
              " '0.4_1',\n",
              " '0.2_1',\n",
              " '0.3_1',\n",
              " '0.9_0',\n",
              " '0.9_1',\n",
              " '0.7_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.9_0',\n",
              " '0.5_1',\n",
              " '0.3_1',\n",
              " '0.9_0',\n",
              " '0.8_1',\n",
              " '0.3_1',\n",
              " '0.3_1',\n",
              " '0.1_1',\n",
              " '0.7_1',\n",
              " '0.1_1',\n",
              " '0.6_1',\n",
              " '0.4_1',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.2_1',\n",
              " '0.2_0',\n",
              " '0.9_1',\n",
              " '0.9_1',\n",
              " '0.0_1',\n",
              " '0.3_0',\n",
              " '0.9_1',\n",
              " '0.6_1',\n",
              " '0.9_0',\n",
              " '0.8_1',\n",
              " '0.7_1',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06B0DBCFEFHP"
      },
      "source": [
        "X = train[train_features]\n",
        "test = test[train_features]\n",
        "\n",
        "f_cats = [f for f in X.columns if \"_cat\" in f]"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}